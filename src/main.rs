use chrono::prelude::*;
use clap::Parser;
use csv;
use flate2::read::MultiGzDecoder;
use indicatif::{ProgressBar, ProgressStyle};
use num_cpus;
use rayon::prelude::*;
use std::collections::{HashMap, HashSet};
use std::error::Error;
use std::fmt;
use std::fs::{self, File, OpenOptions};
use std::io::{BufRead, BufReader, Read, Write};
use std::path::{Path, PathBuf};
use noodles::vcf::variant::record::info::field::Value;
use noodles::vcf::io::indexed_reader::IndexedReader;
use noodles::vcf::variant::record::AlternateBases;
use noodles::core::region::Region;
use noodles::csi;

/// Command-line arguments
#[derive(Parser)]
#[command(
    name = "pathogenic",
    about = "Identify pathogenic variants from a VCF using official ClinVar plus 1000 Genomes frequencies (GRCh37 or GRCh38)"
)]
struct Args {
    /// Genome build: must be "GRCh37" (hg19) or "GRCh38" (hg38)
    #[arg(short, long)]
    build: String,

    /// Path to the input VCF (can be uncompressed or gzipped)
    #[arg(short, long, value_name = "FILE")]
    input: PathBuf,
    
    /// Include variants of uncertain significance (VUS)
    #[arg(long)]
    include_vus: bool,
    
    /// Include benign variants
    #[arg(long)]
    include_benign: bool,
    
    /// Generate markdown report (enabled by default)
    #[arg(long, default_value = "true")]
    markdown_report: bool,
}

/// Custom error type for downloads
#[derive(Debug)]
enum DownloadError {
    Io(std::io::Error),
    Reqwest(reqwest::Error),
}

impl fmt::Display for DownloadError {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        match self {
            DownloadError::Io(e) => write!(f, "IO error: {e}"),
            DownloadError::Reqwest(e) => write!(f, "Reqwest error: {e}"),
        }
    }
}
impl Error for DownloadError {}
impl From<std::io::Error> for DownloadError {
    fn from(e: std::io::Error) -> Self {
        DownloadError::Io(e)
    }
}
impl From<reqwest::Error> for DownloadError {
    fn from(e: reqwest::Error) -> Self {
        DownloadError::Reqwest(e)
    }
}

/// Download a remote file with a progress bar using parallel chunk downloads,
/// if the server supports HTTP range requests. Otherwise, fall back to a single-threaded download.
fn download_file(
    url: &str,
    out_path: &Path,
    log_file: &mut File,
) -> Result<(), DownloadError> {
    use std::sync::{
        atomic::{AtomicU64, Ordering},
        Arc,
    };
    use std::thread;

    println!("  -> Starting download from {url}");
    writeln!(log_file, "  -> Starting download from {url}")?;

    let client = reqwest::blocking::Client::new();
    let head_resp = client.head(url).send()?;
    let total_size = head_resp
        .headers()
        .get(reqwest::header::CONTENT_LENGTH)
        .and_then(|s| s.to_str().ok())
        .and_then(|s| s.parse::<u64>().ok())
        .unwrap_or(0);
    let accept_ranges = head_resp
        .headers()
        .get(reqwest::header::ACCEPT_RANGES)
        .and_then(|s| s.to_str().ok())
        .unwrap_or("");

    if total_size == 0 || accept_ranges != "bytes" {
        println!("  -> Server does not support parallel downloads; falling back to single-threaded download.");
        writeln!(log_file, "  -> Server does not support parallel downloads; falling back to single-threaded download.")?;
        let mut response = client.get(url).send()?;
        let pb = ProgressBar::new(total_size);
        pb.set_style(
            ProgressStyle::default_bar()
                .template("{spinner:.green} [{elapsed_precise}] [{bar:40.cyan/blue}] {bytes}/{total_bytes} ({eta})")
                .unwrap()
                .progress_chars("=>-"),
        );
        let mut file = File::create(out_path)?;
        let mut downloaded: u64 = 0;
        let mut buffer = [0u8; 8192];
        loop {
            let bytes_read = response.read(&mut buffer)?;
            if bytes_read == 0 { break; }
            file.write_all(&buffer[..bytes_read])?;
            downloaded += bytes_read as u64;
            pb.set_position(downloaded);
        }
        pb.finish_with_message("Download complete");
        return Ok(());
    }

    let num_chunks = num_cpus::get();
    let chunk_size = total_size / num_chunks as u64;
    let mut ranges = Vec::new();
    for i in 0..num_chunks {
        let start = i as u64 * chunk_size;
        let end = if i == num_chunks - 1 { total_size - 1 } else { (i as u64 + 1) * chunk_size - 1 };
        ranges.push((start, end));
    }

    let progress = Arc::new(AtomicU64::new(0));
    let mut handles = Vec::new();

    for (i, (start, end)) in ranges.into_iter().enumerate() {
        let client = client.clone();
        let url = url.to_string();
        let progress = Arc::clone(&progress);
        let handle = thread::spawn(move || -> Result<(usize, Vec<u8>), DownloadError> {
            let range_header = format!("bytes={}-{}", start, end);
            let mut resp = client.get(&url)
                .header(reqwest::header::RANGE, range_header)
                .send()?;
            let mut buf = Vec::new();
            let mut local_buf = [0u8; 8192];
            loop {
                let n = resp.read(&mut local_buf)?;
                if n == 0 { break; }
                buf.extend_from_slice(&local_buf[..n]);
                progress.fetch_add(n as u64, Ordering::Relaxed);
            }
            Ok((i, buf))
        });
        handles.push(handle);
    }

    let pb = ProgressBar::new(total_size);
    pb.set_style(
        ProgressStyle::default_bar()
            .template("{spinner:.green} [{elapsed_precise}] [{bar:40.cyan/blue}] {pos}/{total_bytes} ({eta})")
            .unwrap()
            .progress_chars("=>-"),
    );

    while progress.load(Ordering::Relaxed) < total_size {
        pb.set_position(progress.load(Ordering::Relaxed));
        std::thread::sleep(std::time::Duration::from_millis(100));
    }
    pb.finish_with_message("Download complete");

    let mut chunks: Vec<(usize, Vec<u8>)> = Vec::with_capacity(handles.len());
    for handle in handles {
        let res = handle.join().map_err(|_| {
            DownloadError::Io(std::io::Error::new(std::io::ErrorKind::Other, "Thread join error"))
        })??;
        chunks.push(res);
    }
    chunks.sort_by_key(|(i, _)| *i);
    let mut file = File::create(out_path)?;
    for (_i, data) in chunks {
        file.write_all(&data)?;
    }
    Ok(())
}

/// Parse the semicolon-delimited INFO field into a HashMap
fn parse_info_field(info_str: &str) -> HashMap<String, String> {
    let mut map = HashMap::new();
    for item in info_str.split(';') {
        if item.is_empty() {
            continue;
        }
        let mut kv = item.splitn(2, '=');
        let key = kv.next().unwrap_or("").to_string();
        let val = kv.next().unwrap_or("").to_string();
        map.insert(key, val);
    }
    map
}

/// Convert ClinVar review status to a star rating
fn review_status_to_stars(status: Option<&str>) -> u8 {
    match status {
        Some(s) if s.contains("practice guideline") => 4,
        Some(s) if s.contains("reviewed by expert panel") => 3,
        Some(s) if s.contains("criteria provided, multiple submitters, no conflicts") => 2,
        Some(s) if s.contains("criteria provided, single submitter") => 1,
        _ => 0,
    }
}


/// Custom error to unify reading different VCFs (ClinVar or 1000G)
enum VcfReadError {
    Io(std::io::Error),
    Parse(std::num::ParseIntError),
}

impl From<std::io::Error> for VcfReadError {
    fn from(e: std::io::Error) -> Self {
        VcfReadError::Io(e)
    }
}

impl From<std::num::ParseIntError> for VcfReadError {
    fn from(e: std::num::ParseIntError) -> Self {
        VcfReadError::Parse(e)
    }
}

impl fmt::Display for VcfReadError {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        match self {
            VcfReadError::Io(e) => write!(f, "IO error during VCF read: {}", e),
            VcfReadError::Parse(e) => write!(f, "Parse error during VCF read: {}", e),
        }
    }
}

/// A specialized type for records from the ClinVar VCF
#[derive(Debug, Clone)]
struct ClinVarRecord {
    chr: String,
    pos: u32,
    ref_allele: String,
    alt_allele: String,
    clnsig: String,
    is_alt_pathogenic: bool,
    gene: Option<String>,
    allele_id: Option<i32>,
    clnrevstat: Option<String>,
    clndn: Option<String>,
    af_esp: Option<f64>,
    af_exac: Option<f64>,
    af_tgp: Option<f64>,
    clnsig_category: String, // "pathogenic", "benign", "vus", or "conflicting"
}

/// Container for ClinVar variants keyed by (chr, pos, ref, alt)
type ClinVarMap = HashMap<(String, u32, String, String), ClinVarRecord>;

/// Parse a single line from the ClinVar VCF
fn parse_clinvar_line(line: &str, include_vus: bool, include_benign: bool) -> Option<Vec<ClinVarRecord>> {
    if line.starts_with('#') || line.trim().is_empty() {
        return None;
    }

    let mut fields = line.split('\t');
    let chrom = fields.next()?.to_string();
    let pos_str = fields.next()?;
    let _ = fields.next(); // ID
    let ref_allele = fields.next()?;
    let alt_allele = fields.next()?;
    let _ = fields.next(); // QUAL
    let _ = fields.next(); // FILTER
    let info_str = fields.next()?;

    let pos_num = pos_str.parse::<u32>().ok()?;

    let chr_norm = if chrom.eq_ignore_ascii_case("chrM") || chrom.eq_ignore_ascii_case("chrMT") {
        "MT".to_string()
    } else if let Some(stripped) = chrom.strip_prefix("chr") {
        stripped.to_string()
    } else {
        chrom.clone()
    };

    let alt_list: Vec<&str> = alt_allele.split(',').collect();
    let info_map = parse_info_field(info_str);

    let clnsig_opt = info_map.get("CLNSIG");
    if clnsig_opt.is_none() {
        return None;
    }
    let clnsig_str = clnsig_opt.unwrap();

    // Filter variants based on clinical significance and command-line flags
    let contains_pathogenic = clnsig_str.contains("Pathogenic") || clnsig_str.contains("Likely_pathogenic");
    let contains_benign = clnsig_str.contains("Benign") || clnsig_str.contains("Likely_benign");
    let contains_vus = clnsig_str.contains("Uncertain_significance");
    let contains_conflicting = clnsig_str.contains("Conflicting_interpretations_of_pathogenicity");
    
    // Determine the variant classification category
    let clnsig_category = if contains_pathogenic && !contains_benign {
        "pathogenic"
    } else if contains_benign && !contains_pathogenic {
        "benign"
    } else if contains_vus {
        "vus"
    } else if contains_conflicting {
        "conflicting"
    } else {
        "other"
    };
    
    // Skip variants that don't match our inclusion criteria
    if !((contains_pathogenic) || 
         (include_vus && (contains_vus || contains_conflicting)) || 
         (include_benign && contains_benign))
    {
        return None;
    }

    // Determine if the variant is pathogenic for filtering in the match phase
    let is_alt_pathogenic = contains_pathogenic && !(contains_benign);

    let gene_opt = info_map
        .get("GENEINFO")
        .map(|g| g.split(':').next().unwrap_or(g).to_string());
    let allele_id_opt = info_map.get("ALLELEID").and_then(|a| a.parse::<i32>().ok());
    let clnrevstat = info_map.get("CLNREVSTAT").map(|s| s.to_string());
    let clndn = info_map.get("CLNDN").cloned();
    let af_esp = info_map.get("AF_ESP").and_then(|s| s.parse::<f64>().ok());
    let af_exac = info_map.get("AF_EXAC").and_then(|s| s.parse::<f64>().ok());
    let af_tgp = info_map.get("AF_TGP").and_then(|s| s.parse::<f64>().ok());

    let mut recs = Vec::with_capacity(alt_list.len());
    for alt_a in alt_list {
        recs.push(ClinVarRecord {
            chr: chr_norm.clone(),
            pos: pos_num,
            ref_allele: ref_allele.to_string(),
            alt_allele: alt_a.to_string(),
            clnsig: clnsig_str.to_string(),
            is_alt_pathogenic,
            gene: gene_opt.clone(),
            allele_id: allele_id_opt,
            clnrevstat: clnrevstat.clone(),
            clndn: clndn.clone(),
            af_esp,
            af_exac,
            af_tgp,
            clnsig_category: clnsig_category.to_string(),
        });
    }
    Some(recs)
}

/// Parse the ClinVar VCF in parallel
fn parse_clinvar_vcf_gz(
    path_gz: &Path,
    include_vus: bool,
    include_benign: bool,
    log_file: &mut File,
) -> Result<(ClinVarMap, String), Box<dyn Error>> {
    println!("[STEP] Parsing ClinVar VCF: {}", path_gz.display());
    writeln!(log_file, "[STEP] Parsing ClinVar VCF: {}", path_gz.display())?;

    // Extract file date from header if present
    let mut file_date = String::new();
    let file = File::open(&path_gz)?;
    let decoder = MultiGzDecoder::new(file);
    let reader = BufReader::new(decoder);

    let mut lines = Vec::new();

    for line_result in reader.lines() {
        let line = line_result?;

        if line.starts_with("##fileDate=") {
            file_date = line.trim().replace("##fileDate=", "");
        } else if line.starts_with('#') {
            // Skip other header lines
            continue;
        } else {
            // Non-header line, add to batch for parallel processing
            lines.push(line);
        }
    }

    println!("  -> Found {} non-header lines.", lines.len());
    writeln!(log_file, "  -> Found {} non-header lines.", lines.len())?;

    println!("  -> Parsing in parallel with {} threads...", num_cpus::get());
    writeln!(
        log_file,
        "  -> Parsing in parallel with {} threads...",
        num_cpus::get()
    )?;

    let pb = ProgressBar::new(lines.len() as u64);
    pb.set_style(
        ProgressStyle::default_bar()
            .template("{spinner:.green} [{elapsed_precise}] {bar:40.cyan/blue} {pos}/{len} ({eta})")
            .unwrap()
            .progress_chars("=>-"),
    );

    let chunk_maps: Vec<ClinVarMap> = lines
        .par_iter()
        .map(|line| {
            pb.inc(1);
            match parse_clinvar_line(line, include_vus, include_benign) {
                None => HashMap::new(),
                Some(records) => {
                    let mut local_map = HashMap::with_capacity(records.len());
                    for r in records {
                        let key = (r.chr.clone(), r.pos, r.ref_allele.clone(), r.alt_allele.clone());
                        local_map.insert(key, r);
                    }
                    local_map
                }
            }
        })
        .collect();

    pb.finish_with_message("Parsing complete.");

    println!("  -> Merging {} map chunks...", chunk_maps.len());
    writeln!(log_file, "  -> Merging {} map chunks...", chunk_maps.len())?;

    // Combine maps into a single map
    let mut final_map = HashMap::new();
    for cm in chunk_maps {
        final_map.extend(cm);
    }

    println!("  -> Final ClinVar map size: {}", final_map.len());
    writeln!(log_file, "  -> Final ClinVar map size: {}", final_map.len())?;
    Ok((final_map, file_date))
}

/// A specialized type for user input variants
#[derive(Debug)]
struct InputVariant {
    chr: String,
    pos: u32,
    ref_allele: String,
    alts: Vec<(String, bool)>, // (alt_allele, is_present_in_genotype)
    genotype: String,
}

/// Attempt to parse a single user line from VCF
fn parse_input_line(line: &str) -> Option<(String, InputVariant)> {
    if line.starts_with('#') || line.trim().is_empty() {
        return None;
    }

    let mut fields = line.split('\t');
    let chrom = fields.next()?.to_string();
    let pos_str = fields.next()?;
    let _ = fields.next(); // ID
    let ref_allele = fields.next()?;
    let alt_allele = fields.next()?;
    let _ = fields.next(); // QUAL
    let _ = fields.next(); // FILTER
    let _ = fields.next(); // INFO

    let mut rest_cols = Vec::new();
    for c in fields {
        rest_cols.push(c);
    }

    let pos_num = pos_str.parse::<u32>().ok()?;
    let chr_fixed = if chrom.eq_ignore_ascii_case("chrM") || chrom.eq_ignore_ascii_case("chrMT") {
        "MT".to_string()
    } else if let Some(stripped) = chrom.strip_prefix("chr") {
        stripped.to_string()
    } else {
        chrom.to_string()
    };

    let alt_list: Vec<String> = alt_allele.split(',').map(|s| s.to_string()).collect();
    let mut present_flags = HashSet::new();

    // Attempt to parse genotype from the next columns
    // Usually the first of rest_cols is the FORMAT, second is the sample data
    let genotype = if !rest_cols.is_empty() {
        let format_str = rest_cols[0];
        let format_items: Vec<&str> = format_str.split(':').collect();
        if let Some(gt_index) = format_items.iter().position(|&f| f == "GT") {
            if rest_cols.len() > 1 {
                let sample_str = rest_cols[1];
                let sample_items: Vec<&str> = sample_str.split(':').collect();
                if gt_index < sample_items.len() {
                    sample_items[gt_index].to_string()
                } else {
                    "1/1".to_string() 
                }
            } else {
                "1/1".to_string()
            }
        } else {
            "1/1".to_string()
        }
    } else {
        "1/1".to_string()
    };

    if !genotype.is_empty() {
        let split_gt: Vec<&str> = genotype.split(&['/', '|'][..]).collect();
        for g in split_gt {
            if let Ok(idx) = g.parse::<usize>() {
                if idx >= 1 {
                    present_flags.insert(idx);
                }
            }
        }
    }

    let mut alts = Vec::with_capacity(alt_list.len());
    for (i, alt_a) in alt_list.into_iter().enumerate() {
        let alt_idx = i + 1;
        let is_present = present_flags.contains(&alt_idx);
        alts.push((alt_a, is_present));
    }

    Some((line.to_string(), InputVariant {
        chr: chr_fixed,
        pos: pos_num,
        ref_allele: ref_allele.to_string(),
        alts,
        genotype,
    }))
}

/// Parse the user input VCF (can be gzipped or uncompressed)
fn parse_input_vcf(path: &Path, log_file: &mut File) -> Result<Vec<(String, InputVariant)>, Box<dyn Error>> {
    println!(
        "[STEP] Parsing user input VCF: {}",
        path.display()
    );
    writeln!(
        log_file,
        "[STEP] Parsing user input VCF: {}",
        path.display()
    )?;

    if !path.exists() {
        return Err(format!("User input VCF not found: {}", path.display()).into());
    }

    // Check if path is gzipped by extension
    let mut lines = Vec::new();
    if let Some(ext) = path.extension() {
        if ext == "gz" {
            let file = File::open(path)?;
            let decoder = MultiGzDecoder::new(file);
            let reader = BufReader::new(decoder);
            for l in reader.lines() {
                lines.push(l?);
            }
        } else {
            let file = File::open(path)?;
            let reader = BufReader::new(file);
            for l in reader.lines() {
                lines.push(l?);
            }
        }
    } else {
        let file = File::open(path)?;
        let reader = BufReader::new(file);
        for l in reader.lines() {
            lines.push(l?);
        }
    }

    println!(
        "  -> Loaded user VCF ({} lines). Using {} CPU cores.",
        lines.len(),
        num_cpus::get()
    );
    writeln!(
        log_file,
        "  -> Loaded user VCF ({} lines). Using {} CPU cores.",
        lines.len(),
        num_cpus::get()
    )?;

    let total = lines.len() as u64;
    let pb = ProgressBar::new(total);
    pb.set_style(
        ProgressStyle::default_bar()
            .template("{spinner:.green} [{elapsed_precise}] {bar:40.cyan/blue} {pos}/{len} ({eta})")
            .unwrap()
            .progress_chars("=>-"),
    );

    let chunk_variants: Vec<Vec<(String, InputVariant)>> = lines
        .par_iter()
        .map(|line| {
            pb.inc(1);
            match parse_input_line(line) {
                None => vec![],
                Some((l, iv)) => vec![(l, iv)],
            }
        })
        .collect();

    pb.finish_with_message("User input parse complete.");

    let final_list: Vec<(String, InputVariant)> = chunk_variants.into_iter().flatten().collect();
    println!("  -> Parsed {} variants from user input.", final_list.len());
    writeln!(
        log_file,
        "  -> Parsed {} variants from user input.",
        final_list.len()
    )?;
    Ok(final_list)
}

/// A specialized type for records from the ClinVar pathogenic summary TSV.
/// These fields are used for annotation in the final output.
#[derive(Debug, Clone)]
struct ClinVarTsvRecord {
    molecular_consequence: Option<String>,
    functional_consequence: Option<String>,
    mode_of_inheritance: Option<String>,
    preferred_values: Option<String>,
    citations: Option<String>,
    comments: Option<String>,
    family_data: Option<String>,
    record_status: Option<String>,
    description: Option<String>,
    date_last_evaluated: Option<String>,
}

/// Parse the ClinVar pathogenic summary TSV for deeper annotation
fn parse_clinvar_tsv(
    tsv_path: &Path,
    build: &str,
    log_file: &mut File,
) -> Result<HashMap<(String, u32, String, String), ClinVarTsvRecord>, Box<dyn Error>> {
    println!("[STEP] Parsing ClinVar summary TSV: {}", tsv_path.display());
    writeln!(
        log_file,
        "[STEP] Parsing ClinVar summary TSV: {}",
        tsv_path.display()
    )?;

    let file = File::open(tsv_path)?;
    let reader: Box<dyn BufRead> = if let Some(ext) = tsv_path.extension() {
        if ext == "xz" {
            Box::new(BufReader::new(xz2::read::XzDecoder::new(file)))
        } else {
            Box::new(BufReader::new(file))
        }
    } else {
        Box::new(BufReader::new(file))
    };

    let mut line_count = 0;
    let mut map = HashMap::new();
    let mut header_indices: Option<HashMap<String, usize>> = None;

    // We handle GRCh37 or GRCh38 columns
    let want_37 = build == "GRCH37";

    for line_result in reader.lines() {
        let line = line_result?;
        line_count += 1;

        if line_count == 1 {
            // Header row
            let headers: Vec<&str> = line.split('\t').collect();
            let mut idx_map = HashMap::new();
            for (i, h) in headers.iter().enumerate() {
                idx_map.insert(h.to_string(), i);
            }
            header_indices = Some(idx_map);
            continue;
        }
        let headers_map = header_indices.as_ref().ok_or("No header row found")?;
        let cols: Vec<&str> = line.split('\t').collect();
        if cols.len() < 28 {
            continue;
        }

        let c_chr = if want_37 {
            headers_map.get("GRCh37_Chromosome")
        } else {
            headers_map.get("GRCh38_Chromosome")
        };
        let c_pos = if want_37 {
            headers_map.get("GRCh37_PositionVCF")
        } else {
            headers_map.get("GRCh38_PositionVCF")
        };
        let c_ref = if want_37 {
            headers_map.get("GRCh37_ReferenceAlleleVCF")
        } else {
            headers_map.get("GRCh38_ReferenceAlleleVCF")
        };
        let c_alt = if want_37 {
            headers_map.get("GRCh37_AlternateAlleleVCF")
        } else {
            headers_map.get("GRCh38_AlternateAlleleVCF")
        };

        if c_chr.is_none() || c_pos.is_none() || c_ref.is_none() || c_alt.is_none() {
            continue;
        }
        let chr_val = cols[*c_chr.unwrap()].trim();
        let pos_val = cols[*c_pos.unwrap()].trim();
        let ref_val = cols[*c_ref.unwrap()].trim();
        let alt_val = cols[*c_alt.unwrap()].trim();

        let pos_parsed = pos_val.parse::<u32>().unwrap_or(0);
        if chr_val.is_empty() || pos_parsed == 0 || ref_val.is_empty() || alt_val.is_empty() {
            continue;
        }

        // Normalize chromosome
        let chr_norm = if chr_val.eq_ignore_ascii_case("chrM")
            || chr_val.eq_ignore_ascii_case("chrMT")
        {
            "MT".to_string()
        } else if let Some(stripped) = chr_val.strip_prefix("chr") {
            stripped.to_string()
        } else {
            chr_val.to_string()
        };

        let rec = ClinVarTsvRecord {
            molecular_consequence: headers_map
                .get("MolecularConsequence")
                .and_then(|idx| cols.get(*idx).map(|s| s.to_string()))
                .filter(|s| !s.is_empty()),
            functional_consequence: headers_map
                .get("FunctionalConsequence")
                .and_then(|idx| cols.get(*idx).map(|s| s.to_string()))
                .filter(|s| !s.is_empty()),
            mode_of_inheritance: headers_map
                .get("ModeOfInheritance")
                .and_then(|idx| cols.get(*idx).map(|s| s.to_string()))
                .filter(|s| !s.is_empty()),
            preferred_values: headers_map
                .get("PreferredValues")
                .and_then(|idx| cols.get(*idx).map(|s| s.to_string()))
                .filter(|s| !s.is_empty()),
            citations: headers_map
                .get("Citations")
                .and_then(|idx| cols.get(*idx).map(|s| s.to_string()))
                .filter(|s| !s.is_empty()),
            comments: headers_map
                .get("Comments")
                .and_then(|idx| cols.get(*idx).map(|s| s.to_string()))
                .filter(|s| !s.is_empty()),
            family_data: headers_map
                .get("FamilyData")
                .and_then(|idx| cols.get(*idx).map(|s| s.to_string()))
                .filter(|s| !s.is_empty()),
            record_status: headers_map
                .get("RecordStatus")
                .and_then(|idx| cols.get(*idx).map(|s| s.to_string()))
                .filter(|s| !s.is_empty()),
            description: headers_map
                .get("Description")
                .and_then(|idx| cols.get(*idx).map(|s| s.to_string()))
                .filter(|s| !s.is_empty()),
            date_last_evaluated: headers_map
                .get("DateLastEvaluated")
                .and_then(|idx| cols.get(*idx).map(|s| s.to_string()))
                .filter(|s| !s.is_empty()),
        };

        let key = (chr_norm, pos_parsed, ref_val.to_string(), alt_val.to_string());
        map.insert(key, rec);
    }

    println!("  -> Parsed {} lines from summary TSV.", line_count - 1);
    writeln!(
        log_file,
        "  -> Parsed {} lines from summary TSV.",
        line_count - 1
    )?;
    Ok(map)
}

/// Our final output record combining user input, ClinVar VCF, ClinVar TSV, and 1000G frequencies.
#[derive(Debug)]
struct FinalRecord {
    chr: String,
    pos: u32,
    ref_allele: String,
    alt_allele: String,
    clnsig: String,
    is_alt_pathogenic: bool,
    gene: Option<String>,
    allele_id: Option<i32>,
    genotype: String,
    review_stars: u8,
    af_esp: Option<f64>,
    af_exac: Option<f64>,
    af_tgp: Option<f64>,
    clndn: Option<String>,
    molecular_consequence: Option<String>,
    functional_consequence: Option<String>,
    mode_of_inheritance: Option<String>,
    preferred_values: Option<String>,
    citations: Option<String>,
    comments: Option<String>,
    family_data: Option<String>,
    record_status: Option<String>,
    description: Option<String>,
    date_last_evaluated: Option<String>,
    af_afr: Option<f64>,
    af_amr: Option<f64>,
    af_eas: Option<f64>,
    af_eur: Option<f64>,
    af_sas: Option<f64>,
    clnsig_category: String,
}

/// Get the numeric order for sorting chromosomes
fn get_chromosome_order(chr: &str) -> usize {
    if chr == "X" { 
        return 23; 
    } else if chr == "Y" { 
        return 24; 
    } else if chr == "MT" { 
        return 25; 
    } else if let Ok(num) = chr.parse::<usize>() {
        return num;
    } else {
        return 100; // Any other chromosome types will be sorted last
    }
}

fn main() -> Result<(), Box<dyn Error>> {
    let mut log_file = OpenOptions::new()
        .create(true)
        .append(true)
        .open("pathogenic.log")?;

    println!("=== Genetic Variant Finder ===");
    writeln!(log_file, "=== Genetic Variant Finder ===")?;

    let now: DateTime<Utc> = Utc::now();
    println!("[LOG] Timestamp: {}", now.to_rfc3339());
    writeln!(log_file, "[LOG] Timestamp: {}", now.to_rfc3339())?;

    let args = Args::parse();
    let build = args.build.to_uppercase();
    let input_path = args.input.clone();
    let include_vus = args.include_vus;
    let include_benign = args.include_benign;

    println!("[LOG] Genome Build: {}", build);
    writeln!(log_file, "[LOG] Genome Build: {}", build)?;
    println!("[LOG] Input File: {}", input_path.display());
    writeln!(log_file, "[LOG] Input File: {}", input_path.display())?;
    println!("[LOG] Include VUS: {}", include_vus);
    writeln!(log_file, "[LOG] Include VUS: {}", include_vus)?;
    println!("[LOG] Include Benign: {}", include_benign);
    writeln!(log_file, "[LOG] Include Benign: {}", include_benign)?;

    println!("[STEP] Checking arguments...");
    writeln!(log_file, "[STEP] Checking arguments...")?;
    if build != "GRCH37" && build != "GRCH38" {
        return Err("Genome build must be 'GRCh37' or 'GRCh38'".into());
    }
    if !input_path.exists() {
        return Err(format!("Input VCF not found: {}", input_path.display()).into());
    }

    // Create reports directory if it doesn't exist
    let reports_dir = Path::new("reports");
    fs::create_dir_all(reports_dir)?;
    println!("[STEP] Ensuring reports directory exists: {}", reports_dir.display());
    writeln!(log_file, "[STEP] Ensuring reports directory exists: {}", reports_dir.display())?;

    // 1) CLINVAR VCF / TBI
    let (clinvar_url, clinvar_tbi_url) = match build.as_str() {
        "GRCH37" => (
            "https://ftp.ncbi.nih.gov/pub/clinvar/vcf_GRCh37/clinvar.vcf.gz",
            "https://ftp.ncbi.nih.gov/pub/clinvar/vcf_GRCh37/clinvar.vcf.gz.tbi",
        ),
        "GRCH38" => (
            "https://ftp.ncbi.nih.gov/pub/clinvar/vcf_GRCh38/clinvar.vcf.gz",
            "https://ftp.ncbi.nih.gov/pub/clinvar/vcf_GRCh38/clinvar.vcf.gz.tbi",
        ),
        _ => unreachable!(),
    };

    let clinvar_dir = Path::new("clinvar_data");
    fs::create_dir_all(&clinvar_dir)?;
    let clinvar_vcf_path = clinvar_dir.join(format!("clinvar_{}.vcf.gz", build));
    let clinvar_tbi_path = clinvar_dir.join(format!("clinvar_{}.vcf.gz.tbi", build));

    // 2) CLINVAR TSV for deeper annotation
    // We'll store it in the same directory
    let tsv_path = clinvar_dir.join("clinvar_summary_pathogenic.tsv.xz");
    let tsv_url = "https://raw.githubusercontent.com/SauersML/pathogenic/main/clinvar_summary_pathogenic.tsv.xz";

    // 3) 1000 GENOMES FREQUENCY FILE
    let onekg_url = match build.as_str() {
        "GRCH37" => "https://ftp.ensembl.org/pub/grch37/variation/vcf/homo_sapiens/1000GENOMES-phase_3.vcf.gz",
        "GRCH38" => "https://ftp.ensembl.org/pub/current_variation/vcf/homo_sapiens/1000GENOMES-phase_3.vcf.gz",
        _ => unreachable!(),
    };
    let onekg_file_path = clinvar_dir.join(format!("1000GENOMES-phase_3_{}.vcf.gz", build));

    println!("[STEP] Ensuring necessary files exist locally...");
    writeln!(log_file, "[STEP] Ensuring necessary files exist locally...")?;

    // Download CLINVAR VCF if not found or corrupt
    if !clinvar_vcf_path.exists() {
        println!("  -> Missing ClinVar VCF for {build}, downloading...");
        writeln!(
            log_file,
            "  -> Missing ClinVar VCF for {build}, downloading..."
        )?;
        download_file(clinvar_url, &clinvar_vcf_path, &mut log_file)?;
    } else {
        println!("  -> Found local ClinVar VCF: {}", clinvar_vcf_path.display());
        writeln!(log_file, "  -> Found local ClinVar VCF: {}", clinvar_vcf_path.display())?;
        // Check if corrupt
        let testf = File::open(&clinvar_vcf_path)?;
        let mut test_decoder = MultiGzDecoder::new(testf);
        let mut buffer = [0u8; 1024];
        if let Err(e) = test_decoder.read(&mut buffer) {
            println!("  -> ClinVar VCF is corrupt ({e}), re-downloading...");
            writeln!(
                log_file,
                "  -> ClinVar VCF is corrupt ({e}), re-downloading..."
            )?;
            fs::remove_file(&clinvar_vcf_path)?;
            download_file(clinvar_url, &clinvar_vcf_path, &mut log_file)?;
        }
    }

    // Download CLINVAR TBI if missing
    if !clinvar_tbi_path.exists() {
        println!("  -> Missing ClinVar TBI, downloading...");
        writeln!(log_file, "  -> Missing ClinVar TBI, downloading...")?;
        download_file(clinvar_tbi_url, &clinvar_tbi_path, &mut log_file)?;
    } else {
        println!("  -> Found local ClinVar TBI: {}", clinvar_tbi_path.display());
        writeln!(log_file, "  -> Found local ClinVar TBI: {}", clinvar_tbi_path.display())?;
    }

    // Download the 1000G frequency file if missing
    if !onekg_file_path.exists() {
        println!("  -> Missing 1000 Genomes frequency file for {build}, downloading...");
        writeln!(
            log_file,
            "  -> Missing 1000 Genomes frequency file for {build}, downloading..."
        )?;
        download_file(onekg_url, &onekg_file_path, &mut log_file)?;
    } else {
        println!("  -> Found local 1000 Genomes: {}", onekg_file_path.display());
        writeln!(log_file, "  -> Found local 1000 Genomes: {}", onekg_file_path.display())?;
        let testf = File::open(&onekg_file_path)?;
        let mut test_decoder = MultiGzDecoder::new(testf);
        let mut buffer = [0u8; 1024];
        if let Err(e) = test_decoder.read(&mut buffer) {
            println!("  -> 1000 Genomes freq file is corrupt ({e}), re-downloading...");
            writeln!(
                log_file,
                "  -> 1000 Genomes freq file is corrupt ({e}), re-downloading..."
            )?;
            fs::remove_file(&onekg_file_path)?;
            download_file(onekg_url, &onekg_file_path, &mut log_file)?;
        }
    }

    // Download ClinVar summary TSV if missing
    if !tsv_path.exists() {
        println!("  -> Missing ClinVar summary TSV, downloading...");
        writeln!(log_file, "  -> Missing ClinVar summary TSV, downloading...")?;
        download_file(tsv_url, &tsv_path, &mut log_file)?;
    } else {
        println!("  -> Found local ClinVar summary TSV: {}", tsv_path.display());
        writeln!(
            log_file,
            "  -> Found local ClinVar summary TSV: {}",
            tsv_path.display()
        )?;
    }

    // Parse ClinVar VCF for pathogenic variants
    let (clinvar_map, _file_date) = parse_clinvar_vcf_gz(&clinvar_vcf_path, include_vus, include_benign, &mut log_file)?;
    
    // Parse the ClinVar TSV for deeper annotation
    let tsv_map = parse_clinvar_tsv(&tsv_path, &build, &mut log_file)?;

    // Parse the user VCF input
    let input_variants = parse_input_vcf(&input_path, &mut log_file)?;

    println!("[STEP] Matching user variants with ClinVar and 1000G...");
    writeln!(
        log_file,
        "[STEP] Matching user variants with ClinVar and 1000G..."
    )?;

    // Structure to hold temporary records during matching process
    struct TempRecord {
        chr: String,
        pos: u32,
        ref_allele: String,
        alt_allele: String,
        clnsig: String,
        is_alt_pathogenic: bool,
        gene: Option<String>,
        allele_id: Option<i32>,
        genotype: String,
        review_stars: u8,
        af_esp: Option<f64>,
        af_exac: Option<f64>,
        af_tgp: Option<f64>,
        clndn: Option<String>,
        clnsig_category: String,
    }

    // Match user variants with ClinVar
    println!("[STEP] Matching user variants to ClinVar...");
    writeln!(log_file, "[STEP] Matching user variants to ClinVar...")?;
    
    let pb = ProgressBar::new(input_variants.len() as u64);
    pb.set_style(
        ProgressStyle::default_bar()
            .template("{spinner:.green} [{elapsed_precise}] {bar:40.cyan/blue} {pos}/{len} ({eta})")
            .unwrap()
            .progress_chars("=>-"),
    );

    let temp_results: Vec<TempRecord> = input_variants
        .par_iter()
        .flat_map_iter(|(_, iv)| {
            let mut local_found = Vec::new();
            for (alt_a, is_present) in &iv.alts {
                if !is_present {
                    continue;
                }
                let key = (iv.chr.clone(), iv.pos, iv.ref_allele.clone(), alt_a.clone());
                if let Some(cv) = clinvar_map.get(&key) {
                    // Include all variants that match our criteria (controlled by flags when parsing)
                    // rather than checking is_alt_pathogenic here, as we did before
                    let genotype = iv.genotype.clone();
                    let review_stars = review_status_to_stars(cv.clnrevstat.as_deref());
                    local_found.push(TempRecord {
                        chr: cv.chr.clone(),
                        pos: cv.pos,
                        ref_allele: cv.ref_allele.clone(),
                        alt_allele: cv.alt_allele.clone(),
                        clnsig: cv.clnsig.clone(),
                        is_alt_pathogenic: cv.is_alt_pathogenic,
                        gene: cv.gene.clone(),
                        allele_id: cv.allele_id,
                        genotype,
                        review_stars,
                        af_esp: cv.af_esp,
                        af_exac: cv.af_exac,
                        af_tgp: cv.af_tgp,
                        clndn: cv.clndn.clone(),
                        clnsig_category: cv.clnsig_category.clone(),
                    });
                }
            }
            pb.inc(1);
            local_found
        })
        .collect();

    pb.finish_with_message("ClinVar matching complete.");

    println!("  -> Matched {} variants in ClinVar", temp_results.len());
    writeln!(
        log_file,
        "  -> Matched {} variants in ClinVar",
        temp_results.len()
    )?;

    // Collect keys of interest from temp_results for 1000 Genomes frequency lookup
    let keys_of_interest: HashSet<(String, u32, String, String)> = temp_results
        .iter()
        .map(|r| (r.chr.clone(), r.pos, r.ref_allele.clone(), r.alt_allele.clone()))
        .collect();

    // Stream 1000 Genomes VCF and extract frequencies for keys_of_interest
    println!("[STEP] Querying 1000 Genomes frequency VCF using CSI index: {}", onekg_file_path.display());
    writeln!(log_file, "[STEP] Querying 1000 Genomes frequency VCF using CSI index: {}", onekg_file_path.display())?;
    let onekg_index_path = clinvar_dir.join(format!("1000GENOMES-phase_3_{}_vcf.gz.csi", build));
    if !onekg_index_path.exists() {
        println!("  -> Missing 1000 Genomes CSI index for {}. Downloading...", build);
        writeln!(log_file, "  -> Missing 1000 Genomes CSI index for {}. Downloading...", build)?;
        download_file(
            if build == "GRCH37" {
                "https://ftp.ensembl.org/pub/grch37/variation/vcf/homo_sapiens/1000GENOMES-phase_3.vcf.gz.csi"
            } else {
                "https://ftp.ensembl.org/pub/current_variation/vcf/homo_sapiens/1000GENOMES-phase_3.vcf.gz.csi"
            },
            &onekg_index_path,
            &mut log_file
        )?;
    }

    // Improved error handling
    println!("  -> Opening 1000 Genomes file: {}", onekg_file_path.display());
    let file = match File::open(&onekg_file_path) {
        Ok(f) => f,
        Err(e) => {
            let error_msg = format!("Failed to open 1000 Genomes file: {}", e);
            println!("ERROR: {}", error_msg);
            writeln!(log_file, "ERROR: {}", error_msg)?;
            return Err(error_msg.into());
        }
    };

    println!("  -> Opening 1000 Genomes CSI index: {}", onekg_index_path.display());
    let index_file = match File::open(&onekg_index_path) {
        Ok(f) => f,
        Err(e) => {
            let error_msg = format!("Failed to open 1000 Genomes CSI index: {}", e);
            println!("ERROR: {}", error_msg);
            writeln!(log_file, "ERROR: {}", error_msg)?;
            return Err(error_msg.into());
        }
    };

    println!("  -> Reading CSI index...");
    let mut csi_reader = csi::io::Reader::new(index_file);
    let index = match csi_reader.read_index() {
        Ok(idx) => idx,
        Err(e) => {
            let error_msg = format!("Failed to read CSI index: {}", e);
            println!("ERROR: {}", error_msg);
            writeln!(log_file, "ERROR: {}", error_msg)?;
            return Err(error_msg.into());
        }
    };

    println!("  -> Creating indexed reader...");
    let mut reader = IndexedReader::new(file, index);

    println!("  -> Reading VCF header...");
    let header = match reader.read_header() {
        Ok(h) => h,
        Err(e) => {
            let error_msg = format!("Failed to read VCF header: {}", e);
            println!("ERROR: {}", error_msg);
            writeln!(log_file, "ERROR: {}", error_msg)?;
            return Err(error_msg.into());
        }
    };

    println!("  -> Setting up frequency mapping...");
    let mut onekg_freqs: HashMap<(String, u32, String, String), (Option<f64>, Option<f64>, Option<f64>, Option<f64>, Option<f64>)> = HashMap::with_capacity(keys_of_interest.len());
    let mut unique_regions: HashSet<(String, u32)> = HashSet::new();
    for (chr, pos, _ref, _alt) in keys_of_interest.iter() {
        unique_regions.insert((chr.clone(), *pos));
    }

    println!("  -> Will query {} unique genomic positions", unique_regions.len());
    writeln!(log_file, "  -> Will query {} unique genomic positions", unique_regions.len())?;

    // Store the size before moving unique_regions
    let unique_regions_count = unique_regions.len();

    // Progress bar for region querying
    let pb = ProgressBar::new(unique_regions_count as u64);
    pb.set_style(
        ProgressStyle::default_bar()
            .template("{spinner:.green} [{elapsed_precise}] {bar:40.cyan/blue} {pos}/{len} ({eta})")
            .unwrap()
            .progress_chars("=>-"),
    );

    // Add success/error counters
    let mut successful_queries = 0;
    let mut failed_queries = 0;

    for (chr, pos) in unique_regions {
        pb.inc(1);
        let region_str = format!("{}:{}-{}", chr, pos, pos);
        let region_obj = match region_str.parse::<Region>() {
            Ok(r) => r,
            Err(e) => {
                // Just log and continue to the next region
                writeln!(log_file, "  -> Failed to parse region {}: {}", region_str, e)?;
                failed_queries += 1;
                continue;
            }
        };
        
        match reader.query(&header, &region_obj) {
            Ok(mut query) => {
                successful_queries += 1;
                while let Some(record_result) = query.next() {
                    match record_result {
                        Ok(record) => {
                            // Process the record as before
                            let record_chr = record.reference_sequence_name().to_string();
                            let record_pos = match record.variant_start() {
                                Some(Ok(pos)) => pos,
                                _ => continue, // Skip if we can't get position
                            };
                            let record_ref = record.reference_bases().to_string();
                            
                            // Get alternative alleles
                            let record_alts: Vec<String> = record.alternate_bases()
                                .iter()
                                .filter_map(Result::ok)
                                .map(|alt| alt.to_string())
                                .collect();
                            
                            let info = record.info();
                            
                            for (alt_idx, alt) in record_alts.iter().enumerate() {
                                let key = (record_chr.clone(), record_pos.get() as u32, record_ref.clone(), alt.clone());
                                if keys_of_interest.contains(&key) {
                                    // Helper function to extract the frequency for a specific alternate allele from the INFO field
                                    let get_freq = |key: &str, alt_idx: usize| -> Option<f64> {
                                        match info.get(&header, key) {
                                            Some(Ok(Some(Value::Array(array)))) => {
                                                match array {
                                                    noodles::vcf::variant::record::info::field::value::Array::Float(values) => {
                                                        let mut iter = values.iter();
                                                        if let Some(Ok(Some(f))) = iter.nth(alt_idx) {
                                                            // Convert f32 to f64 without dereferencing
                                                            Some(f64::from(f))
                                                        } else {
                                                            None
                                                        }
                                                    },
                                                    _ => None, // Handle other Array variants (e.g., Integer, String)
                                                }
                                            },
                                            _ => None,
                                        }
                                    };
                                    let afr = get_freq("AFR", alt_idx);
                                    let amr = get_freq("AMR", alt_idx);
                                    let eas = get_freq("EAS", alt_idx);
                                    let eur = get_freq("EUR", alt_idx);
                                    let sas = get_freq("SAS", alt_idx);
                                    onekg_freqs.insert(key, (afr, amr, eas, eur, sas));
                                }
                            }
                        },
                        Err(e) => {
                            // Just log error and continue
                            writeln!(log_file, "  -> Error processing record for region {}: {}", region_str, e)?;
                        }
                    }
                }
            },
            Err(e) => {
                // Log the error and continue
                writeln!(log_file, "  -> Failed to query region {}: {}", region_str, e)?;
                failed_queries += 1;
            }
        }
    }

    pb.finish_with_message("1000 Genomes querying complete");

    println!("  -> Successfully queried {}/{} regions", successful_queries, unique_regions_count);
    println!("  -> Failed to query {} regions", failed_queries);
    writeln!(log_file, "  -> Successfully queried {}/{} regions", successful_queries, unique_regions_count)?;
    writeln!(log_file, "  -> Failed to query {} regions", failed_queries)?;
    println!("  -> Extracted frequencies for {} variants", onekg_freqs.len());
    writeln!(log_file, "  -> Extracted frequencies for {} variants", onekg_freqs.len())?;

    // Next, we combine with 1000G frequency data
    let mut final_records: Vec<FinalRecord> = Vec::new();
    for r in &temp_results {
        let key = (r.chr.clone(), r.pos, r.ref_allele.clone(), r.alt_allele.clone());
        let (af_afr, af_amr, af_eas, af_eur, af_sas) = match onekg_freqs.get(&key) {
            None => (None, None, None, None, None),
            Some((afr, amr, eas, eur, sas)) => (*afr, *amr, *eas, *eur, *sas),
        };
        let annotation = tsv_map.get(&key);
        let final_rec = FinalRecord {
            chr: r.chr.clone(),
            pos: r.pos,
            ref_allele: r.ref_allele.clone(),
            alt_allele: r.alt_allele.clone(),
            clnsig: r.clnsig.clone(),
            is_alt_pathogenic: r.is_alt_pathogenic,
            gene: r.gene.clone(),
            allele_id: r.allele_id,
            genotype: r.genotype.clone(),
            review_stars: r.review_stars,
            af_esp: r.af_esp,
            af_exac: r.af_exac,
            af_tgp: r.af_tgp,
            clndn: r.clndn.clone(),
            molecular_consequence: annotation.and_then(|ann| ann.molecular_consequence.clone()),
            functional_consequence: annotation.and_then(|ann| ann.functional_consequence.clone()),
            mode_of_inheritance: annotation.and_then(|ann| ann.mode_of_inheritance.clone()),
            preferred_values: annotation.and_then(|ann| ann.preferred_values.clone()),
            citations: annotation.and_then(|ann| ann.citations.clone()),
            comments: annotation.and_then(|ann| ann.comments.clone()),
            family_data: annotation.and_then(|ann| ann.family_data.clone()),
            record_status: annotation.and_then(|ann| ann.record_status.clone()),
            description: annotation.and_then(|ann| ann.description.clone()),
            date_last_evaluated: annotation.and_then(|ann| ann.date_last_evaluated.clone()),
            af_afr,
            af_amr,
            af_eas,
            af_eur,
            af_sas,
            clnsig_category: r.clnsig_category.clone(),
        };
        final_records.push(final_rec);
    }

    // Sort final records by chromosome, then by position
    final_records.sort_by(|a, b| {
        let a_order = get_chromosome_order(&a.chr);
        let b_order = get_chromosome_order(&b.chr);
        
        match a_order.cmp(&b_order) {
            std::cmp::Ordering::Equal => a.pos.cmp(&b.pos),
            other => other
        }
    });

    // Get input filename without extension for output naming
    let input_filename = input_path
        .file_stem()
        .and_then(|s| s.to_str())
        .unwrap_or("input")
        .to_string()
        .replace(".vcf", "")  // Remove any additional .vcf if present in the stem
        .replace(".gz", "");  // Remove any additional .gz if present in the stem

    // Determine the analysis type for the filename
    let analysis_type = match (include_vus, include_benign) {
        (false, false) => "pathogenic_only",
        (true, false) => "pathogenic_vus",
        (false, true) => "pathogenic_benign",
        (true, true) => "pathogenic_vus_benign",
    };

    // Create the output filename using the input file name, analysis type, and timestamp
    let timestamp = now.format("%Y%m%d_%H%M%S");
    let output_filename = format!(
        "{}_{}_{}.csv",
        input_filename,
        analysis_type,
        timestamp
    );
    
    let output_path = reports_dir.join(output_filename);

    // Create a statistics file with the same base name
    let stats_filename = format!(
        "{}_{}_{}_stats.txt",
        input_filename,
        analysis_type,
        timestamp
    );
    let stats_path = reports_dir.join(stats_filename);
    
    println!("[STEP] Writing final CSV to: {}", output_path.display());
    writeln!(log_file, "[STEP] Writing final CSV to: {}", output_path.display())?;
    let mut wtr = csv::Writer::from_path(&output_path)?;

    wtr.write_record(&[
        "Chromosome",
        "Position",
        "Reference Allele",
        "Alternate Allele",
        "Clinical Significance",
        "Is Alt Pathogenic",
        "Significance Category",
        "Gene",
        "ClinVar Allele ID",
        "CLNDN",
        "Genotype",
        "Review Stars",
        "AF_ESP",
        "AF_EXAC",
        "AF_TGP",
        "Molecular Consequence",
        "Functional Consequence",
        "Mode of Inheritance",
        "Preferred Values",
        "Citations",
        "Comments",
        "Family Data",
        "Record Status",
        "Description",
        "Date Last Evaluated",
        "AF_AFR",
        "AF_AMR",
        "AF_EAS",
        "AF_EUR",
        "AF_SAS",
    ])?;

    for rec in &final_records {
        wtr.write_record(&[
            &rec.chr,
            &rec.pos.to_string(),
            &rec.ref_allele,
            &rec.alt_allele,
            &rec.clnsig,
            &rec.is_alt_pathogenic.to_string(),
            &rec.clnsig_category,
            rec.gene.as_deref().unwrap_or(""),
            &rec.allele_id.map(|id| id.to_string()).unwrap_or_default(),
            rec.clndn.as_deref().unwrap_or(""),
            &rec.genotype,
            &rec.review_stars.to_string(),
            &rec.af_esp.map(|f| f.to_string()).unwrap_or_default(),
            &rec.af_exac.map(|f| f.to_string()).unwrap_or_default(),
            &rec.af_tgp.map(|f| f.to_string()).unwrap_or_default(),
            rec.molecular_consequence.as_deref().unwrap_or(""),
            rec.functional_consequence.as_deref().unwrap_or(""),
            rec.mode_of_inheritance.as_deref().unwrap_or(""),
            rec.preferred_values.as_deref().unwrap_or(""),
            rec.citations.as_deref().unwrap_or(""),
            rec.comments.as_deref().unwrap_or(""),
            rec.family_data.as_deref().unwrap_or(""),
            rec.record_status.as_deref().unwrap_or(""),
            rec.description.as_deref().unwrap_or(""),
            rec.date_last_evaluated.as_deref().unwrap_or(""),
            &rec.af_afr.map(|f| f.to_string()).unwrap_or_default(),
            &rec.af_amr.map(|f| f.to_string()).unwrap_or_default(),
            &rec.af_eas.map(|f| f.to_string()).unwrap_or_default(),
            &rec.af_eur.map(|f| f.to_string()).unwrap_or_default(),
            &rec.af_sas.map(|f| f.to_string()).unwrap_or_default(),
        ])?;
    }

    wtr.flush()?;
    println!(
        "Done. Wrote {} variants to {}",
        final_records.len(),
        output_path.display()
    );
    writeln!(
        log_file,
        "Done. Wrote {} variants to {}",
        final_records.len(),
        output_path.display()
    )?;

    // Generate and write statistics file
    println!("[STEP] Writing statistics file to: {}", stats_path.display());
    writeln!(log_file, "[STEP] Writing statistics file to: {}", stats_path.display())?;
    
    // Collect statistics
    let mut unique_genes = HashSet::new();
    let mut category_counts = HashMap::new();
    let mut af_ranges = HashMap::new();
    
    for rec in &final_records {
        // Count unique genes
        if let Some(gene) = &rec.gene {
            unique_genes.insert(gene.clone());
        }
        
        // Count by classification category
        *category_counts.entry(rec.clnsig_category.clone()).or_insert(0) += 1;
        
        // Group by allele frequency range (for EAS, EUR, AFR, AMR, SAS)
        let add_af_range = |af: Option<f64>, population: &str, ranges: &mut HashMap<String, i32>| {
            if let Some(freq) = af {
                let range = if freq < 0.001 {
                    "< 0.1%"
                } else if freq < 0.01 {
                    "0.1% - 1%"
                } else if freq < 0.05 {
                    "1% - 5%"
                } else if freq < 0.10 {
                    "5% - 10%"
                } else {
                    "> 10%"
                };
                
                let key = format!("{}_{}", population, range);
                *ranges.entry(key).or_insert(0) += 1;
            }
        };
        
        add_af_range(rec.af_afr, "AFR", &mut af_ranges);
        add_af_range(rec.af_amr, "AMR", &mut af_ranges);
        add_af_range(rec.af_eas, "EAS", &mut af_ranges);
        add_af_range(rec.af_eur, "EUR", &mut af_ranges);
        add_af_range(rec.af_sas, "SAS", &mut af_ranges);
    }
    
    // Write statistics file
    let stats_path_clone = stats_path.clone();
    let mut stats_file = File::create(&stats_path)?;
    
    writeln!(stats_file, "=== Genetic Variant Finder: Analysis Report ===")?;
    writeln!(stats_file, "Date/Time: {}", now.to_rfc3339())?;
    writeln!(stats_file, "\n=== Analysis Settings ===")?;
    writeln!(stats_file, "Input File: {}", input_path.display())?;
    writeln!(stats_file, "Genome Build: {}", build)?;
    writeln!(stats_file, "Include VUS: {}", include_vus)?;
    writeln!(stats_file, "Include Benign: {}", include_benign)?;
    
    writeln!(stats_file, "\n=== Analysis Results ===")?;
    writeln!(stats_file, "Total Variants Processed: {}", input_variants.len())?;
    writeln!(stats_file, "Total Variants Reported: {}", final_records.len())?;
    writeln!(stats_file, "Unique Genes: {}", unique_genes.len())?;
    
    writeln!(stats_file, "\n=== Variant Classifications ===")?;
    for (category, count) in category_counts.iter() {
        writeln!(stats_file, "{}: {}", category, count)?;
    }
    
    writeln!(stats_file, "\n=== Allele Frequency Distribution ===")?;
    for (range, count) in af_ranges.iter() {
        writeln!(stats_file, "{}: {}", range, count)?;
    }
    
    writeln!(stats_file, "\n=== Population Coverage ===")?;
    let mut pop_coverage = HashMap::new();
    // Count variants with any frequency data for each population
    for rec in &final_records {
        if rec.af_afr.is_some() { *pop_coverage.entry("AFR").or_insert(0) += 1; }
        if rec.af_amr.is_some() { *pop_coverage.entry("AMR").or_insert(0) += 1; }
        if rec.af_eas.is_some() { *pop_coverage.entry("EAS").or_insert(0) += 1; }
        if rec.af_eur.is_some() { *pop_coverage.entry("EUR").or_insert(0) += 1; }
        if rec.af_sas.is_some() { *pop_coverage.entry("SAS").or_insert(0) += 1; }
    }
    
    for (pop, count) in pop_coverage.iter() {
        let percentage = if final_records.is_empty() { 
            0.0 
        } else { 
            (*count as f64 / final_records.len() as f64) * 100.0 
        };
        writeln!(stats_file, "{}: {} variants ({:.1}%)", pop, count, percentage)?;
    }
    
    println!(
        "Done. Wrote statistics to {}",
        stats_path_clone.display()
    );
    writeln!(
        log_file,
        "Done. Wrote statistics to {}",
        stats_path_clone.display()
    )?;

    // Generate markdown report if enabled
    if args.markdown_report {
        // Create the markdown filename
        let markdown_filename = format!(
            "{}_{}_{}_report.md",
            input_filename,
            analysis_type,
            timestamp
        );
        let markdown_path = reports_dir.join(markdown_filename);

        // Collect the command run for inclusion in the report
        let args_vec: Vec<String> = std::env::args().collect();
        let command_run = args_vec.join(" ");

        // Generate the markdown report
        println!("[STEP] Generating markdown report: {}", markdown_path.display());
        writeln!(log_file, "[STEP] Generating markdown report: {}", markdown_path.display())?;

        generate_markdown_report(
            &final_records,
            &markdown_path,
            &args,
            &category_counts,
            &unique_genes,
            &input_path,
            &build,
            input_variants.len(),
            &timestamp.to_string(),
            &command_run,
            &mut log_file,
        )?;

        println!(
            "Done. Wrote markdown report to {}",
            markdown_path.display()
        );
        writeln!(
            log_file,
            "Done. Wrote markdown report to {}",
            markdown_path.display()
        )?;
    }

    Ok(())
}

/// Generate markdown report of found variants with dynamic sections based on analysis settings
fn generate_markdown_report(
    final_records: &[FinalRecord],
    out_path: &Path,
    args: &Args,
    category_counts: &HashMap<String, usize>,
    unique_genes: &HashSet<String>,
    input_path: &Path,
    build: &str,
    total_variants: usize,
    _timestamp: &str,
    command_run: &str,
    log_file: &mut File,
) -> Result<(), Box<dyn Error>> {
    println!("[STEP] Generating markdown report: {}", out_path.display());
    writeln!(log_file, "[STEP] Generating markdown report: {}", out_path.display())?;
    
    let mut md_file = File::create(out_path)?;
    
    // Current date/time for report
    let now: DateTime<Utc> = Utc::now();
    let datetime = now.format("%B %d, %Y @ %H:%M:%S").to_string();
    
    // Group variants by classification and gene for better organization
    let mut gene_pathogenic: HashMap<String, Vec<&FinalRecord>> = HashMap::new();       // Strictly Pathogenic
    let mut gene_likely_pathogenic: HashMap<String, Vec<&FinalRecord>> = HashMap::new(); // Likely Pathogenic
    let mut gene_vus: HashMap<String, Vec<&FinalRecord>> = HashMap::new();              // Uncertain Significance
    let mut gene_conflicting: HashMap<String, Vec<&FinalRecord>> = HashMap::new();      // Conflicting Interpretations
    let mut gene_benign: HashMap<String, Vec<&FinalRecord>> = HashMap::new();           // Strictly Benign
    let mut gene_likely_benign: HashMap<String, Vec<&FinalRecord>> = HashMap::new();    // Likely Benign
    
    // Track which variant types are actually present in the results
    let mut has_pathogenic = false;
    let mut has_likely_pathogenic = false;
    let mut has_vus = false;
    let mut has_conflicting = false;
    let mut has_benign = false;
    let mut has_likely_benign = false;
    
    // Organize variants by type and gene
    for record in final_records {
        let gene_name = record.gene.clone().unwrap_or_else(|| "Unknown".to_string());
        let clnsig = &record.clnsig;
        
        if record.clnsig_category == "pathogenic" {
            // Split pathogenic variants based on their specific clnsig value
            if clnsig.contains("Likely_pathogenic") && !clnsig.contains("Pathogenic") {
                has_likely_pathogenic = true;
                gene_likely_pathogenic.entry(gene_name).or_default().push(record);
            } else {
                // Either strictly Pathogenic or Pathogenic/Likely_pathogenic
                has_pathogenic = true;
                gene_pathogenic.entry(gene_name).or_default().push(record);
            }
        } else if record.clnsig_category == "vus" && args.include_vus {
            has_vus = true;
            gene_vus.entry(gene_name).or_default().push(record);
        } else if record.clnsig_category == "benign" && args.include_benign {
            // Split benign variants based on their specific clnsig value
            if clnsig.contains("Likely_benign") && !clnsig.contains("Benign") {
                has_likely_benign = true;
                gene_likely_benign.entry(gene_name).or_default().push(record);
            } else {
                // Either strictly Benign or Benign/Likely_benign
                has_benign = true;
                gene_benign.entry(gene_name).or_default().push(record);
            }
        } else if record.clnsig_category == "conflicting" && args.include_vus {
            has_conflicting = true;
            gene_conflicting.entry(gene_name).or_default().push(record);
        }
    }
    
    // Create a list of sections for Table of Contents and report generation
    struct Section<'a> {
        id: String,
        title: String,
        present: bool,
        variants: HashMap<String, Vec<&'a FinalRecord>>,
    }
    
    let mut sections = vec![
        Section {
            id: "disclaimer".to_string(),
            title: "Disclaimer".to_string(),
            present: true, // Always include disclaimer
            variants: HashMap::new(),
        },
        Section {
            id: "summary".to_string(),
            title: "Summary".to_string(),
            present: true, // Always include summary
            variants: HashMap::new(),
        }
    ];
    
    // Add pathogenic sections if present
    if has_pathogenic {
        sections.push(Section {
            id: "pathogenic-variants".to_string(),
            title: "Pathogenic Variants".to_string(),
            present: true,
            variants: gene_pathogenic,
        });
    }
    
    if has_likely_pathogenic {
        sections.push(Section {
            id: "likely-pathogenic-variants".to_string(),
            title: "Likely Pathogenic Variants".to_string(),
            present: true,
            variants: gene_likely_pathogenic,
        });
    }
    
    // Dynamically add sections based on what's included and present
    if has_vus && args.include_vus {
        sections.push(Section {
            id: "uncertain-significance-variants".to_string(),
            title: "Variants of Uncertain Significance".to_string(),
            present: true,
            variants: gene_vus,
        });
    }
    
    if has_conflicting && args.include_vus {
        sections.push(Section {
            id: "conflicting-variants".to_string(),
            title: "Variants with Conflicting Interpretations".to_string(),
            present: true,
            variants: gene_conflicting,
        });
    }
    
    // Add benign sections if present and included
    if has_benign && args.include_benign {
        sections.push(Section {
            id: "benign-variants".to_string(),
            title: "Benign Variants".to_string(),
            present: true,
            variants: gene_benign,
        });
    }
    
    if has_likely_benign && args.include_benign {
        sections.push(Section {
            id: "likely-benign-variants".to_string(),
            title: "Likely Benign Variants".to_string(),
            present: true,
            variants: gene_likely_benign,
        });
    }
    
    // Always add understanding section at the end
    sections.push(Section {
        id: "understanding-this-report".to_string(),
        title: "Understanding This Report".to_string(),
        present: true,
        variants: HashMap::new(),
    });
    
    // Write the header
    writeln!(md_file, "# Genetic Variant Report")?;
    writeln!(md_file)?;
    writeln!(md_file, "**Date / Time Generated:** {}", datetime)?;
    
    // Write the variant types analyzed
    let mut variant_types = Vec::new();
    if has_pathogenic {
        variant_types.push("Pathogenic");
    }
    if has_likely_pathogenic {
        variant_types.push("Likely Pathogenic");
    }
    
    if args.include_vus {
        variant_types.push("Uncertain Significance");
        variant_types.push("Conflicting Interpretations");
    }
    
    if args.include_benign {
        if has_benign {
            variant_types.push("Benign");
        }
        if has_likely_benign {
            variant_types.push("Likely Benign");
        }
    }
    
    writeln!(md_file)?;
    writeln!(md_file, "**Variant Types Analyzed:** {}", variant_types.join(", "))?;
    writeln!(md_file)?;
    
    // Write analysis settings
    writeln!(md_file, "### Analysis Settings:")?;
    writeln!(md_file, "- **Input File:** {}", input_path.display())?;
    writeln!(md_file, "- **Genome Build:** {}", build)?;
    writeln!(md_file, "- **Include VUS:** {}", args.include_vus)?;
    writeln!(md_file, "- **Include Benign:** {}", args.include_benign)?;
    writeln!(md_file)?;
    
    // Write command run
    writeln!(md_file, "**Command Run:**")?;
    writeln!(md_file, "```bash")?;
    writeln!(md_file, "{}", command_run)?;
    writeln!(md_file, "```")?;
    
    // Generate dynamically correct table of contents
    writeln!(md_file)?;
    writeln!(md_file, "---")?;
    writeln!(md_file)?;
    writeln!(md_file, "## Table of Contents")?;
    writeln!(md_file)?;
    
    // Only include sections that are present in the results
    let present_sections: Vec<&Section> = sections.iter()
        .filter(|s| s.present)
        .collect();
    
    for (i, section) in present_sections.iter().enumerate() {
        writeln!(md_file, "{}. [{}](#{})", i + 1, section.title, section.id)?;
    }
    
    writeln!(md_file)?;
    writeln!(md_file, "---")?;
    
    // Generate each section
    for section in sections.iter().filter(|s| s.present) {
        if section.id == "disclaimer" {
            write_disclaimer_section(&mut md_file)?;
        } else if section.id == "summary" {
            write_summary_section(&mut md_file, category_counts, args, final_records.len(), total_variants, unique_genes.len())?;
        } else if section.id == "understanding-this-report" {
            write_understanding_section(&mut md_file)?;
        } else {
            // This is a variant section - use appropriate handler
            write_variant_section(&mut md_file, &section.variants, &section.id, &section.title)?;
        }
    }
    
    println!("  -> Markdown report generated successfully.");
    writeln!(log_file, "  -> Markdown report generated successfully.")?;
    
    Ok(())
}

/// Write the disclaimer section
fn write_disclaimer_section(md_file: &mut File) -> Result<(), Box<dyn Error>> {
    writeln!(md_file, "<a id=\"disclaimer\"></a>")?;
    writeln!(md_file, "# Disclaimer")?;
    writeln!(md_file)?;
    writeln!(md_file, "> **Important:** This report is for informational purposes only and should not be used for medical decisions without consultation with a healthcare professional. Genetic data interpretation is complex and may change over time as scientific understanding evolves.")?;
    writeln!(md_file)?;
    writeln!(md_file, "---")?;
    
    Ok(())
}

/// Write the summary section
fn write_summary_section(
    md_file: &mut File,
    category_counts: &HashMap<String, usize>,
    args: &Args,
    variants_reported: usize,
    variants_processed: usize,
    unique_genes_count: usize,
) -> Result<(), Box<dyn Error>> {
    writeln!(md_file, "<a id=\"summary\"></a>")?;
    writeln!(md_file, "## Summary")?;
    writeln!(md_file)?;
    writeln!(md_file, "This report contains genetic variants found in your genome that match clinical databases. The variants are categorized by clinical significance:")?;
    writeln!(md_file)?;

    // Additional summary stats
    writeln!(md_file)?;
    writeln!(md_file, "**Total Number of Genetic Variants Processed:** {}", variants_processed)?;
    writeln!(md_file)?;
    writeln!(md_file, "**Number of Unique Genes with Identified Variants:** {}", unique_genes_count)?;
    writeln!(md_file)?;
    
    // Summary table
    writeln!(md_file, "| Category | Count |")?;
    writeln!(md_file, "|---------|-------|")?;
    
    let pathogenic_count = category_counts.get("pathogenic").unwrap_or(&0);
    let likely_pathogenic_count = category_counts.get("likely_pathogenic").unwrap_or(&0);
    let conflicting_count = category_counts.get("conflicting").unwrap_or(&0);
    let vus_count = category_counts.get("vus").unwrap_or(&0);
    let likely_benign_count = category_counts.get("likely_benign").unwrap_or(&0);
    let benign_count = category_counts.get("benign").unwrap_or(&0);
    
    writeln!(md_file, "| Pathogenic | {} |", pathogenic_count)?;
    writeln!(md_file, "| Likely Pathogenic | {} |", likely_pathogenic_count)?;
    
    if args.include_vus {
        writeln!(md_file, "| Conflicting | {} |", conflicting_count)?;
        writeln!(md_file, "| Uncertain Significance | {} |", vus_count)?;
    } else {
        writeln!(md_file, "| Conflicting | Not Analyzed |")?;
        writeln!(md_file, "| Uncertain Significance | Not Analyzed |")?;
    }
    
    if args.include_benign {
        writeln!(md_file, "| Likely Benign | {} |", likely_benign_count)?;
        writeln!(md_file, "| Benign | {} |", benign_count)?;
    } else {
        writeln!(md_file, "| Likely Benign | Not Analyzed |")?;
        writeln!(md_file, "| Benign | Not Analyzed |")?;
    }
    
    writeln!(md_file, "| **Total Variants Reported** | **{}** |", variants_reported)?;
    writeln!(md_file)?;
    writeln!(md_file, "---")?;
    
    Ok(())
}

/// Write the variant section (pathogenic, VUS, conflicting, or benign)
fn write_variant_section(
    md_file: &mut File,
    gene_variants: &HashMap<String, Vec<&FinalRecord>>,
    section_id: &str,
    section_title: &str,
) -> Result<(), Box<dyn Error>> {
    writeln!(md_file, "<a id=\"{}\"></a>", section_id)?;
    writeln!(md_file, "## {}", section_title)?;
    writeln!(md_file)?;
    
    if gene_variants.is_empty() {
        writeln!(md_file, "No {} were found in this analysis.", section_title.to_lowercase())?;
        writeln!(md_file)?;
        writeln!(md_file, "---")?;
        return Ok(());
    }
    
    // Summary table
    writeln!(md_file, "### Summary Table")?;
    writeln!(md_file)?;
    writeln!(md_file, "| Gene | Variant Location | DNA Change | Condition | Genotype, Zygosity | Clinical Significance | African Freq | American Freq | East Asian Freq | European Freq | South Asian Freq |")?;
    writeln!(md_file, "|:-----|:-------|:----------|:----------|:---------|:---------|:---------------------|:---------------------|:---------------------|:---------------------|:---------------------|")?;
    
    // Track variant IDs for the details section
    let mut variant_id = 1;
    let mut summary_entries = Vec::new();
    
    // Collect all variants from all genes into a single list
    let mut all_variants: Vec<(&String, &FinalRecord)> = Vec::new();
    for (gene, variants) in gene_variants {
        for variant in variants {
            all_variants.push((gene, *variant));
        }
    }
    
    // Sort all variants by chromosome and position first
    all_variants.sort_by(|(_, a), (_, b)| {
        let a_order = get_chromosome_order(&a.chr);
        let b_order = get_chromosome_order(&b.chr);
        
        match a_order.cmp(&b_order) {
            std::cmp::Ordering::Equal => a.pos.cmp(&b.pos),
            other => other
        }
    });
    
    // Process the sorted variants
    for (gene, variant) in all_variants {
        let chr = &variant.chr;
        let pos = variant.pos;
        let ref_allele = &variant.ref_allele;
        let alt_allele = &variant.alt_allele;
        
        let dna_change = format!("{} -> {}", ref_allele, alt_allele);
        
        // Clean condition field by replacing pipe characters with commas and underscores with spaces
        let condition = match &variant.clndn {
            Some(c) => c.replace('|', ", ").replace('_', " "),
            None => "Not specified".to_string(),
        };
        
        // Determine zygosity from genotype
        let genotype = &variant.genotype;
        let zygosity = if genotype == "1/1" {
            "Homozygous"
        } else if genotype == "0/1" || genotype == "1/0" {
            "Heterozygous"
        } else {
            "Unknown"
        };
        
        let genotype_text = format!("{}, {}", genotype, zygosity);
        
        // Clean clinical significance - just use the classification type without extra data
        let clean_clnsig = variant.clnsig.replace('_', " ");
        
        // Format frequencies as percentages with 2 decimal places
        let format_freq = |f: Option<f64>| -> String {
            match f {
                Some(val) => format!("{:.2}%", val * 100.0),
                None => "N/A".to_string(),
            }
        };
        
        let afr_freq = format_freq(variant.af_afr);
        let amr_freq = format_freq(variant.af_amr);
        let eas_freq = format_freq(variant.af_eas);
        let eur_freq = format_freq(variant.af_eur);
        let sas_freq = format_freq(variant.af_sas);
        
        writeln!(
            md_file,
            "| [{}](#variant-{}) | Chr {}:{} | {} | {} | {} | {} | {} | {} | {} | {} | {} |",
            gene, variant_id, chr, pos, dna_change, condition, genotype_text, 
            clean_clnsig, afr_freq, amr_freq, eas_freq, eur_freq, sas_freq
        )?;
        
        summary_entries.push((gene.clone(), variant, variant_id));
        variant_id += 1;
    }
    
    // Detailed descriptions
    writeln!(md_file)?;
    writeln!(md_file, "### Detailed Descriptions")?;
    writeln!(md_file)?;
    
    for (gene, variant, id) in summary_entries {
        write_variant_details(md_file, &gene, variant, id)?;
        writeln!(md_file)?;
        writeln!(md_file, "---")?;
        writeln!(md_file)?;
    }
    
    Ok(())
}

/// Write details for a single variant
fn write_variant_details(
    md_file: &mut File,
    gene: &str,
    variant: &FinalRecord,
    variant_id: usize,
) -> Result<(), Box<dyn Error>> {
    writeln!(md_file, "<a id=\"variant-{}\"></a>", variant_id)?;
    writeln!(md_file, "### {}. {} ", variant_id, gene)?;
    writeln!(md_file)?;
    writeln!(md_file, "<details open>")?;
    writeln!(md_file, "<summary><strong>Variant Details</strong></summary>")?;
    writeln!(md_file)?;
    
    // Clean condition field by replacing pipe characters with commas and underscores with spaces
    let condition = match &variant.clndn {
        Some(c) => c.replace('|', ", ").replace('_', " "),
        None => "Not specified".to_string(),
    };
    
    writeln!(md_file, "**Associated Condition:** {}", condition)?;
    writeln!(md_file)?;
    
    // Location
    writeln!(md_file, "**Location:** Chromosome {}, Position {}", variant.chr, variant.pos)?;
    writeln!(md_file)?;
    
    // DNA Change
    writeln!(
        md_file,
        "**DNA Change:** Your DNA has `{}` where the reference genome has `{}`",
        variant.alt_allele, variant.ref_allele
    )?;
    writeln!(md_file)?;
    
    // Genotype / Zygosity
    let zygosity = if variant.genotype == "1/1" {
        "Homozygous (both copies of the gene have this variant)"
    } else if variant.genotype == "0/1" || variant.genotype == "1/0" {
        "Heterozygous (one copy of the gene has this variant)"
    } else {
        ""
    };
    
    writeln!(
        md_file,
        "**Genotype / Zygosity:** {}, {}",
        variant.genotype, zygosity
    )?;
    writeln!(md_file)?;
    
    // Clinical significance - replace underscores with spaces
    let clean_clnsig = variant.clnsig.replace('_', " ");
    writeln!(md_file, "**Clinical Significance of Variant:** {}", clean_clnsig)?;
    writeln!(md_file)?;
    
    // Molecular effects (if available)
    if let Some(mol_effect) = &variant.molecular_consequence {
        if !mol_effect.is_empty() {
            writeln!(md_file, "**Molecular Effects:**")?;
            writeln!(md_file, "- Type: {}", mol_effect.replace('_', " "))?;
            writeln!(md_file)?;
        }
    }
    
    // Population frequencies
    let has_any_freq = variant.af_afr.is_some() || variant.af_amr.is_some() || 
                       variant.af_eas.is_some() || variant.af_eur.is_some() ||
                       variant.af_sas.is_some();
    
    if has_any_freq {
        writeln!(md_file, "**Population Frequencies:** (How common this variant is in different populations)")?;
        writeln!(md_file, "| Population | Frequency |")?;
        writeln!(md_file, "|:-----------|:----------|")?;
        
        // Format frequency helper
        let format_freq = |f: Option<f64>| -> String {
            match f {
                Some(val) => format!("{:.2}%", val * 100.0),
                None => "Not available".to_string(),
            }
        };
        
        if variant.af_afr.is_some() {
            writeln!(md_file, "| African | {} |", format_freq(variant.af_afr))?;
        }
        if variant.af_amr.is_some() {
            writeln!(md_file, "| American | {} |", format_freq(variant.af_amr))?;
        }
        if variant.af_eas.is_some() {
            writeln!(md_file, "| East Asian | {} |", format_freq(variant.af_eas))?;
        }
        if variant.af_eur.is_some() {
            writeln!(md_file, "| European | {} |", format_freq(variant.af_eur))?;
        }
        if variant.af_sas.is_some() {
            writeln!(md_file, "| South Asian | {} |", format_freq(variant.af_sas))?;
        }
        writeln!(md_file)?;
    }
    
    // Review status
    let stars = variant.review_stars;
    let review_status = if stars == 0 {
        " - No assertion criteria provided"
    } else if stars == 1 {
        " ★ - Criteria provided, single submitter"
    } else if stars == 2 {
        " ★★ - Criteria provided, multiple submitters, no conflicts"
    } else if stars == 3 {
        " ★★★ - Criteria provided, reviewed by expert panel"
    } else {
        " ★★★★ - Practice guideline"
    };
    
    writeln!(md_file, "> **Review Status:** {}", review_status)?;
    writeln!(md_file)?;
    
    // Additional fields if available
    if let Some(preferred) = &variant.preferred_values {
        if !preferred.is_empty() {
            writeln!(md_file, "> **Preferred Values:** {}", preferred.replace('_', " "))?;
            writeln!(md_file)?;
        }
    }
    
    if let Some(desc) = &variant.description {
        if !desc.is_empty() {
            writeln!(md_file, "> **Description:** {}", desc.replace('_', " "))?;
            writeln!(md_file)?;
        }
    }
    
    if let Some(citations) = &variant.citations {
        if !citations.is_empty() {
            writeln!(md_file, "> **Research Citations:** {}", citations.replace('_', " "))?;
            writeln!(md_file)?;
        }
    }
    
    if let Some(status) = &variant.record_status {
        if !status.is_empty() {
            writeln!(md_file, "> **Record Status:** {}", status.replace('_', " "))?;
            writeln!(md_file)?;
        }
    }
    
    if let Some(evaluated) = &variant.date_last_evaluated {
        if !evaluated.is_empty() {
            writeln!(md_file, "> **Date Last Evaluated:** {}", evaluated.replace('_', " "))?;
            writeln!(md_file)?;
        }
    }
    
    writeln!(md_file, "</details>")?;
    
    Ok(())
}

/// Write the understanding section of the markdown report
fn write_understanding_section(md_file: &mut File) -> Result<(), Box<dyn Error>> {
    writeln!(md_file, "<a id=\"understanding-this-report\"></a>")?;
    writeln!(md_file, "## Understanding This Report")?;
    writeln!(md_file)?;
    
    writeln!(md_file, "**Clinical Significance Categories:**")?;
    writeln!(md_file)?;
    writeln!(md_file, "- **Pathogenic variants** are genetic changes that have strong evidence for causing disease or health conditions.")?;
    writeln!(md_file)?;
    writeln!(md_file, "- **Likely Pathogenic variants** have good but not definitive evidence suggesting they cause disease.")?;
    writeln!(md_file)?;
    writeln!(md_file, "- **Conflicting Interpretations** are variants where different labs or researchers have come to different conclusions about their significance.")?;
    writeln!(md_file)?;
    writeln!(md_file, "- **Variants of Uncertain Significance (VUS)** are genetic changes where there is currently not enough evidence to determine if they are potentiallyharmful or harmless.")?;
    writeln!(md_file)?;
    writeln!(md_file, "- **Likely Benign variants** have good evidence suggesting they do not cause disease.")?;
    writeln!(md_file)?;
    writeln!(md_file, "- **Benign variants** are genetic changes that are known to be harmless based on strong evidence.")?;
    writeln!(md_file)?;
    
    writeln!(md_file, "**Important Note:** Having a pathogenic or likely pathogenic variant doesn't necessarily mean you will develop the condition, as other factors like environment, lifestyle, and additional genetic factors also play important roles.")?;
    writeln!(md_file)?;
    
    writeln!(md_file, "**Other Terms:**")?;
    writeln!(md_file)?;
    writeln!(md_file, "- **Genotype / Zygosity:**")?;
    writeln!(md_file)?;
    writeln!(md_file, "  - **1/1, Homozygous** means the variant is present on both copies of the gene.")?;
    writeln!(md_file)?;
    writeln!(md_file, "  - **0/1, Heterozygous** means the variant is present on only one copy of the gene.")?;
    writeln!(md_file)?;
    writeln!(md_file, "- **Population Frequencies** show how common the variant is in different populations. Rare variants (low percentage) may be more significant than common ones.")?;
    writeln!(md_file)?;
    writeln!(md_file, "- **Review Stars** indicate the level of review in ClinVar, with more stars representing more thorough evaluation.")?;
    
    Ok(())
}
